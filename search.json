[
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "My Data Analysis",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nNHL Group Project\n\n\n\n\n\n\n\n\n\nDec 17, 2023\n\n\nAyden Currier\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\nDec 11, 2023\n\n\nAyden Currier\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nNFL\n\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nAyden Currier\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nBeer Markets\n\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nByeong-Hak Choe\n\n\n9 min\n\n\n\n\n\n\n  \n\n\n\n\nBeer Markets\n\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nByeong-Hak Choe\n\n\n9 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ayden Currier",
    "section": "",
    "text": "Ayden Currier Majors in Business Administration at Suny Geneseo,In his free time\nhe enjoys playing sports and spending time with his family and friends"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Ayden Currier",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo | Geneseo, NY  Undergraduate in Business Admin | Aug 2022 - May 2026"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Ayden Currier",
    "section": "Experience",
    "text": "Experience\nGrocery Store Stocker| Batavia City School District Custodian | May 2021 - Current"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html",
    "href": "posts/beer-markets/beer-markets.html",
    "title": "Beer Markets",
    "section": "",
    "text": "Let’s analyze the beer_data data:\nbeer_data &lt;- read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "href": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "title": "Beer Markets",
    "section": "Variable Description for beer_data data.frame",
    "text": "Variable Description for beer_data data.frame\nThe following describes the variables in the beer_data data.frame.\n\nhh: Household identifier\n_purchase_desc: Description of the purchase\nquantity: The quantity of beer purchased\nbrand: The brand of beer\ndollar_spent: The amount spent\nbeer_floz: Fluid ounces of beer\nprice_per_floz: Price per fluid ounce\ncontainer: Type of container\npromo: Whether the purchase was on promotion\nmarket: The market where the purchase was made\nDemographics: age, employment status, degree, class of worker (cow), race, and household information like microwave, dishwasher, tvcable, singlefamilyhome, and npeople (number of people in the household)"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "href": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "title": "Beer Markets",
    "section": "Purchase Patterns",
    "text": "Purchase Patterns\nWe’ll explore the purchase patterns in the dataset. This includes understanding the most popular brands, the average quantity purchased, and spending habits across different markets. Here are some specific analyses we can perform:\n\nCalculate the total quantity and spending for each brand.\nFind the average quantity purchased and average spending per purchase.\nCompare the total spending across different markets.\n\nI’ll begin with these analyses and create visualizations to help us understand the data better. Let’s start by calculating the total quantity and spending for each brand.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Reading the CSV file\nbeer_data = pd.read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\n\n# Setting up the visualisation settings\nsns.set(style=\"whitegrid\")\n\n# Calculate total quantity and spending for each brand\nbrand_summary = beer_data.groupby('brand').agg({'quantity':'sum', 'dollar_spent':'sum'}).reset_index()\n\n# Sort by total quantity and spending\nbrand_summary_sorted_quantity = brand_summary.sort_values('quantity', ascending=False)\nbrand_summary_sorted_spent = brand_summary.sort_values('dollar_spent', ascending=False)\n\n\n# Plotting total quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=brand_summary_sorted_quantity, palette='viridis')\nplt.title('Total Quantity of Beer Purchased by Brand')\nplt.xlabel('Total Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting total spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=brand_summary_sorted_spent, palette='viridis')\nplt.title('Total Spending on Beer by Brand')\nplt.xlabel('Total Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar charts above display the total quantity of beer purchased and the total spending by brand. From the looks of it, certain brands dominate in terms of quantity sold and total spending, indicating their popularity.\nNow, let’s calculate the average quantity purchased and average spending per purchase. For this, we’ll consider each row in the dataset as a separate purchase and compute the averages accordingly.\n\n# Calculate average quantity purchased and average spending per purchase\naverage_purchase = beer_data.groupby('brand').agg({\n    'quantity': 'mean', \n    'dollar_spent': 'mean'\n}).reset_index()\n\n# Sort by average quantity and average spending\naverage_purchase_sorted_quantity = average_purchase.sort_values('quantity', ascending=False)\naverage_purchase_sorted_spent = average_purchase.sort_values('dollar_spent', ascending=False)\n\n# Plotting average quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=average_purchase_sorted_quantity, palette='viridis')\nplt.title('Average Quantity of Beer Purchased by Brand')\nplt.xlabel('Average Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting average spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=average_purchase_sorted_spent, palette='viridis')\nplt.title('Average Spending on Beer by Brand')\nplt.xlabel('Average Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe visualizations above depict the average quantity of beer purchased per brand and the average spending per brand. This shows which brands tend to be bought in larger quantities on average and which brands tend to have higher spending per purchase, which could be indicative of their price point or the purchase of premium products.\nNext, we’ll look at the total spending across different markets to see if there are any notable differences in spending habits geographically. To do this, we’ll sum up the spending in each market and visualize it.\n\n# Calculate total spending in each market\nmarket_spending_summary = beer_data.groupby('market').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nmarket_spending_summary_sorted = market_spending_summary.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending in each market\nplt.figure(figsize=(12, 10))\nsns.barplot(x='dollar_spent', y='market', data=market_spending_summary_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Market')\nplt.xlabel('Total Spending')\nplt.ylabel('Market')\nplt.show()\n\n\n\n\nThe bar chart illustrates the total spending on beer by market, showcasing the differences in spending habits across various regions. Some markets have significantly higher spending, which could be due to a variety of factors including market size, consumer preferences, or economic factors.\nNow, let’s move on to the second analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "href": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "title": "Beer Markets",
    "section": "Demographic Analysis",
    "text": "Demographic Analysis\nWe will examine which demographics are buying what kind of beer and whether spending habits vary by demographics such as age, employment, and race. For this, we could look at:\n\nSpending by age group\nSpending by employment status\nSpending by race\n\nI’ll start by analyzing spending by age group.\n\n# Calculate total spending by age group\nage_group_spending = beer_data.groupby('age').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nage_group_spending_sorted = age_group_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by age group\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='age', data=age_group_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Age Group')\nplt.xlabel('Total Spending')\nplt.ylabel('Age Group')\nplt.show()\n\n\n\n\nThe bar chart demonstrates the total spending on beer segmented by age group, highlighting which age groups spend the most on beer. It appears that certain age groups are more dominant in beer spending, which may align with the purchasing power or preferences of those groups.\nNext, we will examine spending by employment status.\n\n# Calculate total spending by employment status\nemployment_spending = beer_data.groupby('employment').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nemployment_spending_sorted = employment_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by employment status\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='employment', data=employment_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Employment Status')\nplt.xlabel('Total Spending')\nplt.ylabel('Employment Status')\nplt.show()\n\n\n\n\nThe visualization shows the total spending on beer by employment status. We can see that certain employment groups, such as full-time workers, are spending more on beer, which might be related to their disposable income.\nFinally, let’s look at spending by race to complete the demographic analysis.\n\n# Calculate total spending by race\nrace_spending = beer_data.groupby('race').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nrace_spending_sorted = race_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by race\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='race', data=race_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Race')\nplt.xlabel('Total Spending')\nplt.ylabel('Race')\nplt.show()\n\n\n\n\nThe bar chart above indicates the total spending on beer broken down by race, highlighting which racial groups account for the most beer spending within the dataset. This could reflect both the demographics of the regions where the data was collected and cultural preferences regarding beer.\nNow, let’s proceed to the third analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "href": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "title": "Beer Markets",
    "section": "Price Sensitivity",
    "text": "Price Sensitivity\nWe’ll look at the price per fluid ounce and see if there are any trends or correlations with the quantity purchased or the brand popularity. To do this, we’ll calculate the average price per fluid ounce for each brand and then visualize how this relates to the average quantity purchased and the total quantity purchased by brand.\nFirst, let’s calculate the average price per fluid ounce for each brand.\n\n# Calculate average price per fluid ounce for each brand\nbrand_price_sensitivity = beer_data.groupby('brand').agg({\n    'price_per_floz': 'mean', \n    'quantity': 'sum'\n}).reset_index()\n\n# Sort by price per fluid ounce\nbrand_price_sensitivity_sorted = brand_price_sensitivity.sort_values('price_per_floz', ascending=True)\n\n# Plotting average price per fluid ounce for each brand and the total quantity purchased\nfig, ax1 = plt.subplots(figsize=(12, 10))\n\ncolor = 'tab:red'\nax1.set_xlabel('Brand')\nax1.set_ylabel('Average Price per Fluid Ounce', color=color)\nax1.bar(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['price_per_floz'], color=color)\nax1.tick_params(axis='y', labelcolor=color)\nax1.set_xticklabels(brand_price_sensitivity_sorted['brand'], rotation=90)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\ncolor = 'tab:blue'\nax2.set_ylabel('Total Quantity Purchased', color=color)  # we already handled the x-label with ax1\nax2.plot(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['quantity'], color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.title('Average Price per Fluid Ounce & Total Quantity Purchased by Brand')\nplt.show()\n\n\n\n\nIn the visualization, we have a bar graph showing the average price per fluid ounce for each brand (in red) and a line graph showing the total quantity purchased for each brand (in blue). This gives us a sense of whether there’s a relationship between the price and the quantity purchased. The x-axis labels are quite compressed due to the number of brands, but we can still observe trends such as whether lower-priced beers tend to be purchased in larger quantities.\nLastly, let’s move to the fourth analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#promotional-impact",
    "href": "posts/beer-markets/beer-markets.html#promotional-impact",
    "title": "Beer Markets",
    "section": "Promotional Impact",
    "text": "Promotional Impact\nWe’ll assess the impact of promotions on the quantity of beer purchased. For this analysis, we can calculate the average quantity purchased with and without promotions and visualize the difference. We’ll do this for each brand to see which brands are most affected by promotions.\nLet’s begin this analysis by looking at the average quantity purchased with and without promotions for each brand.\n\n# Calculate average quantity purchased with and without promotions for each brand\npromo_impact = beer_data.groupby(['brand', 'promo']).agg({'quantity':'mean'}).reset_index()\n\n# Pivot the data to have promo and non-promo side by side for each brand\npromo_impact_pivot = promo_impact.pivot(index='brand', columns='promo', values='quantity').reset_index()\npromo_impact_pivot.columns = ['brand', 'non_promo', 'promo']\n\n# Calculate the difference in average quantity purchased between promo and non-promo\npromo_impact_pivot['promo_impact'] = promo_impact_pivot['promo'] - promo_impact_pivot['non_promo']\n\n# Sort by the impact of promo\npromo_impact_pivot_sorted = promo_impact_pivot.sort_values('promo_impact', ascending=False)\n\n# Plotting the difference in average quantity purchased between promo and non-promo for each brand\nplt.figure(figsize=(12, 10))\nsns.barplot(x='promo_impact', y='brand', data=promo_impact_pivot_sorted, palette='viridis')\nplt.title('Impact of Promotions on Average Quantity Purchased by Brand')\nplt.xlabel('Difference in Average Quantity Purchased (Promo - Non-Promo)')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar chart illustrates the impact of promotions on the average quantity of beer purchased by brand. A positive value indicates that, on average, more beer is purchased when there is a promotion compared to when there isn’t. Some brands appear to be significantly more influenced by promotions, with customers buying more when the products are on sale or promotion.\nThis comprehensive analysis has provided insights into purchase patterns, demographic preferences, price sensitivity, and the impact of promotions on beer purchases."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "NHL Group Project",
    "section": "",
    "text": "In This Data analysis I will be breaking down the files from the Professional hockey data set on the website Kaggle\nFirst off I will identify the variables that will be used throughout this analysis"
  },
  {
    "objectID": "posts/starwars/starwars_df.html",
    "href": "posts/starwars/starwars_df.html",
    "title": "Starwars",
    "section": "",
    "text": "Let’s analyze the starwars data:\nstarwars &lt;- read_csv(\"https://bcdanl.github.io/data/starwars.csv\")"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "href": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "title": "Starwars",
    "section": "Variable Description for starwars data.frame",
    "text": "Variable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#human-vs.-droid",
    "href": "posts/starwars/starwars_df.html#human-vs.-droid",
    "title": "Starwars",
    "section": "Human vs. Droid",
    "text": "Human vs. Droid\n\nggplot(data = \n         starwars %&gt;% \n         filter(species %in% c(\"Human\", \"Droid\"))) +\n  geom_boxplot(aes(x = species, y = mass, \n                   fill = species),\n               show.legend = FALSE)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Welcome to my first blog!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Introduction",
    "section": "",
    "text": "About this project:This project is to show my understanding of data analytics and how to use R studio with the data from Goalies.csv! https://www.kaggle.com/datasets/open-source-sports/professional-hockey-database?select=Goalies.csv"
  },
  {
    "objectID": "project.html#summary-statistics",
    "href": "project.html#summary-statistics",
    "title": "Introduction",
    "section": "Summary Statistics",
    "text": "Summary Statistics\n\nrmarkdown::paged_table(Goalies)\n\n\n\n  \n\n\n\n\nskim(Goalies) %&gt;%\n  select(-n_missing)\n\n\nData summary\n\n\nName\nGoalies\n\n\nNumber of rows\n4278\n\n\nNumber of columns\n23\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n20\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\nskim_variable\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nplayerID\n1\n7\n9\n0\n788\n0\n\n\ntmID\n1\n3\n3\n0\n115\n0\n\n\nlgID\n1\n3\n4\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n1.00\n1980.64\n24.53\n1909\n1972\n1986.0\n1999.0\n2011\n▁▁▂▇▇\n\n\nstint\n1.00\n1.06\n0.24\n1\n1\n1.0\n1.0\n3\n▇▁▁▁▁\n\n\nGP\n1.00\n26.55\n21.03\n1\n7\n23.0\n43.0\n79\n▇▅▃▃▁\n\n\nMin\n1.00\n1502.28\n1238.96\n0\n336\n1257.0\n2467.0\n4697\n▇▅▃▂▁\n\n\nW\n1.00\n11.02\n10.67\n0\n2\n8.0\n18.0\n48\n▇▃▂▁▁\n\n\nL\n1.00\n10.54\n8.77\n0\n3\n9.0\n17.0\n48\n▇▅▂▁▁\n\n\nT.OL\n1.00\n3.25\n3.55\n0\n0\n2.0\n5.0\n22\n▇▂▁▁▁\n\n\nENG\n0.83\n1.71\n1.93\n0\n0\n1.0\n3.0\n12\n▇▂▁▁▁\n\n\nSHO\n1.00\n1.43\n2.21\n0\n0\n0.0\n2.0\n22\n▇▁▁▁▁\n\n\nGA\n1.00\n76.37\n60.43\n0\n20\n68.0\n122.0\n310\n▇▅▃▁▁\n\n\nSA\n0.63\n734.72\n610.57\n0\n165\n604.0\n1205.0\n2488\n▇▅▃▂▁\n\n\nPostGP\n0.34\n6.07\n5.19\n1\n2\n5.0\n8.0\n26\n▇▂▁▁▁\n\n\nPostMin\n0.34\n353.04\n327.80\n0\n120\n252.0\n490.5\n1655\n▇▃▁▁▁\n\n\nPostW\n0.34\n2.81\n3.63\n0\n0\n1.0\n4.0\n16\n▇▂▁▁▁\n\n\nPostL\n0.34\n2.81\n2.20\n0\n1\n3.0\n4.0\n11\n▇▅▂▁▁\n\n\nPostT\n0.02\n0.62\n0.75\n0\n0\n0.5\n1.0\n4\n▇▆▁▁▁\n\n\nPostENG\n0.28\n0.46\n0.74\n0\n0\n0.0\n1.0\n5\n▇▁▁▁▁\n\n\nPostSHO\n0.34\n0.42\n0.85\n0\n0\n0.0\n1.0\n7\n▇▁▁▁▁\n\n\nPostGA\n0.34\n16.12\n13.65\n0\n6\n13.0\n23.0\n74\n▇▅▂▁▁\n\n\nPostSA\n0.19\n183.65\n175.92\n0\n41\n136.0\n265.0\n849\n▇▃▁▁▁\n\n\n\n\n\nName Goalies Number of rows 4278 Number of columns 23 _______________________ Column type frequency:\ncharacter 3 numeric 20 ________________________\nGroup variables None"
  },
  {
    "objectID": "project.html#mpg-and-a-type-of-cars",
    "href": "project.html#mpg-and-a-type-of-cars",
    "title": "Introduction",
    "section": "MPG and a Type of Cars",
    "text": "MPG and a Type of Cars\nThe following boxplot shows how the distribution of highway MPG (hwy) varies by a type of cars (class) :blue_car: :truck: :minibus:.\n\nggplot(data = mpg) +\n  geom_boxplot(aes(x = class, y = hwy, fill = class),\n               show.legend = F) +\n  labs(x = \"Class\", y = \"Highway\\nMPG\") \n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database"
  },
  {
    "objectID": "posts/NFLAnalys/NFL.html",
    "href": "posts/NFLAnalys/NFL.html",
    "title": "NFL",
    "section": "",
    "text": "Let’s analyze the NFL2022_Stuffs data:\nNFL_2022Stuffs &lt;- read.csv(\"https://bcdanl.github.io/data/NFL2022_stuffs.csv\")"
  },
  {
    "objectID": "posts/NFLAnalys/NFL.html#variable-description-for-nfl_2022stuffs-data.frame",
    "href": "posts/NFLAnalys/NFL.html#variable-description-for-nfl_2022stuffs-data.frame",
    "title": "NFL",
    "section": "Variable Description for NFL_2022Stuffs data.frame",
    "text": "Variable Description for NFL_2022Stuffs data.frame\nThe following describes the variables in the NFL_2022Stuffs data.frame.\n\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play game_id: Ten digit identifier for NFL game. drive: Numeric drive number in the game. week: Season week. posteam: String abbreviation for the team with possession. qtr: Quarter of the game (5 is overtime). half_seconds_remaining: Numeric seconds remaining in the half. down: The down for the given play. Basically you get four attempts (aka downs) to move the ball 10 yards (by either running with it or passing it). If you make 10 yards then you get another set of four downs. pass: Binary indicator if the play was a pass play. wp: Estimated winning probability for the posteam given the current situation at the start of the given play."
  },
  {
    "objectID": "posts/NFLAnalys/NFL.html#purchase-patterns",
    "href": "posts/NFLAnalys/NFL.html#purchase-patterns",
    "title": "NFL",
    "section": "Purchase Patterns",
    "text": "Purchase Patterns\nWe’ll explore the Summarize the mean value of pass for each posteam\n\nwp is greater than 20% and less than 75%;\ndown is less than or equal to 2\n\n-half_seconds_remaining is greater than 120.\nI’ll begin with these analyses and create visualizations to help us understand the data better\n\n# Assuming your data frame is named 'NFL_2022Stuffs'\nlibrary(dplyr)\n\n# Filter the data based on the specified conditions\nfiltered_data &lt;- NFL_2022Stuffs %&gt;%\n  filter(wp &gt; 0.20 & wp &lt; 0.75,\n         down &lt;= 2,\n         half_seconds_remaining &gt; 120)\n\n# Group by 'posteam' and calculate the mean of 'pass'\nsummary_data &lt;- filtered_data %&gt;%\n  group_by(posteam) %&gt;%\n  summarize(mean_pass = mean(pass, na.rm = TRUE))\n\n# Print the summary data\nprint(summary_data)\n\n# A tibble: 32 × 2\n   posteam mean_pass\n   &lt;chr&gt;       &lt;dbl&gt;\n 1 ARI         0.553\n 2 ATL         0.4  \n 3 BAL         0.520\n 4 BUF         0.604\n 5 CAR         0.458\n 6 CHI         0.420\n 7 CIN         0.657\n 8 CLE         0.491\n 9 DAL         0.474\n10 DEN         0.493\n# ℹ 22 more rows\n\n\n\nlibrary(ggplot2)\n\n# Assuming 'summary_data' is the resulting data frame from Q2b\n# Reorder 'posteam' based on the mean value of 'mean_pass'\nsummary_data$posteam &lt;- factor(summary_data$posteam, levels = summary_data$posteam[order(summary_data$mean_pass)])\n\n# Create ggplot with geom_point\nggplot(summary_data, aes(x = posteam, y = mean_pass)) +\n  geom_point() +\n  labs(title = \"Mean Value of pass for Each posteam\",\n       x = \"posteam\",\n       y = \"Mean pass value\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\nNFL2022_epa &lt;- read_csv('https://bcdanl.github.io/data/NFL2022_epa.csv')\n\n\n# Assuming you have two data frames: NFL2022_stuffs and NFL2022_epa\n\n# Load required library\n\nlibrary(dplyr)\n\n# Merge data frames based on common variables\n\n# Assuming you have two data frames named NFL2022_stuffs and NFL2022_epa\n\nNFL_2022Stuffs_EPA &lt;- NFL_2022Stuffs %&gt;%\n  left_join(NFL2022_epa %&gt;% select(play_id, passer, receiver, epa), by = \"play_id\") %&gt;%\n  filter(!is.na(passer))\n\n\n# Remove observations with NA in passer\n\nNFL_2022Stuffs_EPA &lt;- NFL_2022Stuffs_EPA %&gt;%\n\nfilter(!is.na(passer))\n\n# Now, NFL2022_stuffs_EPA contains all variables from NFL2022_stuffs\n\n# and the variables passer, receiver, and epa from NFL2022_epa,\n\n# with observations removed if passer is NA.\n\n\n# Assuming you have a data frame named NFL2022_stuffs_EPA\n# and it contains the columns: week, passer, and epa\n\nlibrary(ggplot2)\n\n# Filter data for the specific passers\nselected_passers &lt;- c(\"J.Allen\", \"P.Mahomes\")\nfiltered_data &lt;- NFL_2022Stuffs_EPA %&gt;% filter(passer %in% selected_passers)\n\n# Create ggplot with geom_line\nggplot(filtered_data, aes(x = week, y = epa, color = passer)) +\n  geom_line() +\n  labs(title = \"Weekly Trend of Mean EPA for J.Allen and P.Mahomes\",\n       x = \"Week\",\n       y = \"Mean EPA\") +\n  scale_color_manual(values = c(\"J.Allen\" = \"blue\", \"P.Mahomes\" = \"red\")) +\n  theme_minimal()\n\n\n\n\nThe Bar Chart Represents the total amount of points that each Quarterback is is expected to reach each week in the NFL\nHere I am Calculating the difference between the mean value of epa for “J.Allen” the mean value of epa for “P.Mahomes” for each value of week.\n\n# Assuming you have a data frame named NFL2022_stuffs_EPA\n# and it contains the columns: week, passer, and epa\n\nlibrary(dplyr)\n\n# Filter data for the specific passers\nselected_passers &lt;- c(\"J.Allen\", \"P.Mahomes\")\nfiltered_data &lt;- NFL_2022Stuffs_EPA %&gt;% filter(passer %in% selected_passers)\n\n# Calculate the mean EPA for each passer and week\nmean_epa_per_week &lt;- filtered_data %&gt;%\n  group_by(week, passer) %&gt;%\n  summarize(mean_epa = mean(epa, na.rm = TRUE))\n\n# Pivot the data to have passers as columns\nmean_epa_wide &lt;- pivot_wider(mean_epa_per_week, names_from = passer, values_from = mean_epa)\n\n# Calculate the difference between the mean values\nmean_epa_wide$epa_difference &lt;- mean_epa_wide$J.Allen - mean_epa_wide$P.Mahomes\n\n# View the resulting data frame with the differences\nprint(mean_epa_wide)\n\n# A tibble: 22 × 4\n# Groups:   week [22]\n    week J.Allen P.Mahomes epa_difference\n   &lt;int&gt;   &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;\n 1     1  0.240      0.256       -0.0159 \n 2     2  0.230      0.234       -0.00415\n 3     3  0.235      0.240       -0.00417\n 4     4  0.110      0.320       -0.209  \n 5     5  0.0935     0.310       -0.216  \n 6     6  0.123      0.264       -0.141  \n 7     7  0.276      0.410       -0.135  \n 8     8  0.115      0.368       -0.253  \n 9     9  0.151      0.286       -0.135  \n10    10  0.232      0.325       -0.0927 \n# ℹ 12 more rows\n\n\nHere I am Summarizing the resulting data.frame with the following four variables:\nposteam: String abbreviation for the team with possession. passer: Name of the player who passed a ball to a receiver by initially taking a three-step drop, and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks.) mean_epa: Mean value of epa in 2022 for each passer n_pass: Number of observations for each passer Then find the top 10 NFL passers in 2022 in terms of the mean value of epa, conditioning that n_pass must be greater than or equal to the third quantile level of n_pass.\nDue to issues create an individual column for the term “postseam”\n\n# Load the required library\nlibrary(dplyr)\n\n# Read the CSV file\nNFL2022_epa &lt;- readr::read_csv('https://bcdanl.github.io/data/NFL2022_epa.csv')\n\nlibrary(dplyr)\nlibrary(readr)\n\n# Read the data\nNFL2022_epa &lt;- read_csv('https://bcdanl.github.io/data/NFL2022_epa.csv')\n\n# Assuming 'postseam' is the correct column name, replace it with the correct name if needed\nNFL2022_epa &lt;- NFL2022_epa %&gt;%\n  mutate(posteam = posteam)\n\n# Now, you can use the 'posteam' column in your subsequent analysis\n\n\n# Assuming \"posteam\" is already a column in the dataset, if not, replace it with the actual column name\nNFL2022_epa &lt;- NFL2022_epa %&gt;%\n  mutate(posteam = posteam)\n\n# View the modified dataset\nhead(NFL2022_epa)\n\n# A tibble: 6 × 7\n  play_id game_id         drive posteam receiver  passer      epa\n    &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n1      43 2022_01_BAL_NYJ     1 NYJ     &lt;NA&gt;      &lt;NA&gt;     -0.444\n2      68 2022_01_BAL_NYJ     1 NYJ     &lt;NA&gt;      &lt;NA&gt;      1.47 \n3      89 2022_01_BAL_NYJ     1 NYJ     Mi.Carter J.Flacco -0.492\n4     115 2022_01_BAL_NYJ     1 NYJ     &lt;NA&gt;      &lt;NA&gt;     -0.326\n5     136 2022_01_BAL_NYJ     1 NYJ     &lt;NA&gt;      J.Flacco -2.40 \n6     172 2022_01_BAL_NYJ     1 NYJ     &lt;NA&gt;      &lt;NA&gt;     -0.232\n\n\n\n# Load the required library\nlibrary(dplyr)\n\n# Read the CSV file\nNFL2022_epa &lt;- readr::read_csv('https://bcdanl.github.io/data/NFL2022_epa.csv')\n\n# Assuming \"posteam\" is already a column in the dataset, if not, replace it with the actual column name\nNFL2022_epa &lt;- NFL2022_epa %&gt;%\n  mutate(posteam = posteam)\n\n# Summarize the data\nsummary_data &lt;- NFL2022_epa %&gt;%\n  group_by(posteam, passer) %&gt;%\n  summarize(mean_epa = mean(epa, na.rm = TRUE),\n            n_pass = n())\n\n# Find the third quantile level of n_pass\nquantile_threshold &lt;- quantile(summary_data$n_pass, 0.75)\n\n# Filter data to include only passers with n_pass greater than or equal to the third quantile level\nfiltered_summary_data &lt;- summary_data %&gt;%\n  filter(n_pass &gt;= quantile_threshold)\n\n# Find the top 10 passers based on mean_epa\ntop_10_passers &lt;- filtered_summary_data %&gt;%\n   top_n(10, wt = mean_epa)\n  \n\n# View the resulting data frame\nprint(top_10_passers)\n\n# A tibble: 37 × 4\n# Groups:   posteam [28]\n   posteam passer   mean_epa n_pass\n   &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;int&gt;\n 1 ATL     &lt;NA&gt;     -0.00563    799\n 2 BAL     &lt;NA&gt;      0.0205     803\n 3 BUF     J.Allen   0.172      785\n 4 BUF     &lt;NA&gt;     -0.0404     700\n 5 CAR     &lt;NA&gt;     -0.0155     759\n 6 CHI     &lt;NA&gt;     -0.0232     765\n 7 CIN     J.Burrow  0.153      854\n 8 CIN     &lt;NA&gt;     -0.0725     742\n 9 CLE     &lt;NA&gt;     -0.0253     769\n10 DAL     &lt;NA&gt;     -0.0363     884\n# ℹ 27 more rows"
  }
]